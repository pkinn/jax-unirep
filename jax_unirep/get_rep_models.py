# -*- coding: utf-8 -*-

"""
Models from the original unirep paper.

These models have been edited to work with get_reps. The original get_reps is 
tailored to work with only the 1900, and functions by only applying one layer
to the output of get_embedding. Another method to get reps would be to create 
models without the final mLSTMhiddenstates, Dense, and SoftMax layers.

Generally, you would use these functions in the following fashion:

```python
ADD USAGE HERE
```
"""
from jax.experimental.stax import Dense, Softmax, serial

from .layers import AAEmbedding, mLSTM, mLSTMHiddenStates



def mLSTM1900_gr():
    model_layers = (
        AAEmbedding(10),
        mLSTM(1900),
        )
    return init_fun, apply_fun = serial(*model_layers)
    
def mlstm1900():
    """Return mLSTM1900 model's initialization and forward pass functions.

    The initializer function returned will give us random weights as a starting point.

    The model forward pass function will accept any weights compatible with those
    generated by the initializer function.
    The model implemented here has a trainable embedding,
    one mLSTM layer with 1900 nodes,
    and a single dense layer to predict the next amino acid identity.

    This model is also the default used in `get_reps`.
    """
    model_layers = (
        AAEmbedding(10),
        mLSTM(1900),
        mLSTMHiddenStates(),
        Dense(25),
        Softmax,
    )
    init_fun, apply_fun = serial(*model_layers)
    return init_fun, apply_fun


mlstm1900_init_fun, mlstm1900_apply_fun = mlstm1900()


def mlstm256():
    """Return mLSTM256 model's initialization and forward pass functions.

    The initializer function returned will give us random weights as a starting point.

    The model forward pass function will accept any weights compatible with those
    generated by the initializer function.
    The model implemented here has a trainable embedding,
    four consecutive mLSTM layers each with 256 nodes,
    and a single dense layer to predict the next amino acid identity.

    It's a simpler but nonetheless still complex version of the UniRep model
    that can be trained to generate protein representations.
    """
    model_layers = (
        AAEmbedding(10),
        mLSTM(256),
        mLSTMHiddenStates(),
        mLSTM(256),
        mLSTMHiddenStates(),
        mLSTM(256),
        mLSTMHiddenStates(),
        mLSTM(256),
        mLSTMHiddenStates(),
        Dense(25),
        Softmax,
    )
    init_fun, apply_fun = serial(*model_layers)
    return init_fun, apply_fun


def mlstm256_gr():
    model_layers = (
        AAEmbedding(10),
        mLSTM(256),
        mLSTMHiddenStates(),
        mLSTM(256),
        mLSTMHiddenStates(),
        mLSTM(256),
        mLSTMHiddenStates(),
        mLSTM(256),
        
    )
    init_fun, apply_fun = serial(*model_layers)
    return init_fun, apply_fun


def mlstm64():
    """Return mLSTM64 model's initialization and forward pass functions.

    The initializer function returned will give us random weights as a starting point.

    The model forward pass function will accept any weights compatible with those
    generated by the initializer function.
    The model implemented here has a trainable embedding,
    four consecutive mLSTM layers each with 64 nodes,
    and a single dense layer to predict the next amino acid identity.

    This is the simplest model published by the original UniRep authors.
    """
    model_layers = (
        AAEmbedding(10),
        mLSTM(64),
        mLSTMHiddenStates(),
        mLSTM(64),
        mLSTMHiddenStates(),
        mLSTM(64),
        mLSTMHiddenStates(),
        mLSTM(64),
        mLSTMHiddenStates(),
        Dense(25),
        Softmax,
    )
    init_fun, apply_fun = serial(*model_layers)
    return init_fun, apply_fun

def mlstm64_gr():
    
    model_layers = (
        AAEmbedding(10),
        mLSTM(64),
        mLSTMHiddenStates(),
        mLSTM(64),
        mLSTMHiddenStates(),
        mLSTM(64),
        mLSTMHiddenStates(),
        mLSTM(64),
    )
    init_fun, apply_fun = serial(*model_layers)
    return init_fun, apply_fun